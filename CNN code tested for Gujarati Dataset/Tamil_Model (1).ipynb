{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tamil Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zdMNi33tbcy1",
        "outputId": "4c31cf78-a271-4007-fba7-9cccd00e9e00"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "CATEGORIES = sorted(list(os.listdir(\"/content/drive/MyDrive/OCR For Gujarati Language/Dataset/Gujarati Characters Dataset Photos/28x28\")))\n",
        "IMG_SIZE = 64\n",
        "training_data = []\n",
        "print(len(CATEGORIES))\n",
        "\n",
        "IMG_SIZE = 28\n",
        "\n",
        "#%%\n",
        "#create training data\n",
        "training_data = []\n",
        "\n",
        "def create_training_data(DATADIR):\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATADIR,category)  # create path to dataset\n",
        "        class_num = CATEGORIES.index(category)\n",
        "\n",
        "        for img in tqdm(os.listdir(path)):  # iterate over each image per alphbets\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
        "                img = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  #size to normalize data size\n",
        "                \"\"\"for i in range(len(img)):\n",
        "                    for j in range(len(img[0])):\n",
        "                        img[i][j] = 255 - img[i][j]\"\"\"\n",
        "                training_data.append([img, class_num])  # add this to our training_data\n",
        "            except Exception as e:  # in the interest in keeping the output clean...\n",
        "                pass\n",
        "            #except OSError as e:\n",
        "            #    print(\"OSErrroBad img most likely\", e, os.path.join(path,img))\n",
        "            #except Exception as e:\n",
        "            #    print(\"general exception\", e, os.path.join(path,img))\n",
        "            \n",
        "#loading data from dataset  folders\n",
        "create_training_data(\"/content/drive/MyDrive/OCR For Gujarati Language/Dataset/Gujarati Characters Dataset Photos/28x28\")\n",
        "\n",
        "pickle_out = open(\"GujaratiData.pickle\",\"wb\")\n",
        "pickle.dump(training_data, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "#loading data from pickle file\n",
        "pickle_in = open(\"GujaratiData.pickle\",\"rb\")\n",
        "training_data = pickle.load(pickle_in)\n",
        "\n",
        "print(training_data[0][0].shape)\n",
        "\n",
        "\n",
        "#randomize data\n",
        "random.shuffle(training_data)\n",
        "for sample in training_data[:10]:\n",
        "    print(sample[1])\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for features,label in training_data:\n",
        "    X.append(features)\n",
        "    Y.append(label)\n",
        "\n",
        "#print(X[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE)\n",
        "Y = np.array(Y).reshape(X.shape[0],)\n",
        "\n",
        "seed = 785\n",
        "\n",
        "# split the data into training (80%) and testing (20%)\n",
        "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.20, random_state=seed)\n",
        "print(Y[1])\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], IMG_SIZE, IMG_SIZE, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], IMG_SIZE, IMG_SIZE, 1).astype('float32')\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "\n",
        "# one hot encode outputs\n",
        "Y_train = np_utils.to_categorical(Y_train)\n",
        "Y_test = np_utils.to_categorical(Y_test)\n",
        "\n",
        "num_classes = Y_test.shape[1]\n",
        "\n",
        "plt.imshow((tf.squeeze(X_train[0])))\n",
        "X_train[0].shape\n",
        "\n",
        "#%%\n",
        "#model training\n",
        "model = Sequential()\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=5, input_shape=(IMG_SIZE,IMG_SIZE,1), activation='relu'))\n",
        "model.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(MaxPooling2D(pool_size=3, strides=2))\n",
        "     \n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "      \n",
        "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "       \n",
        "model.add(MaxPooling2D(pool_size=3, strides=2))\n",
        "       \n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Flatten())    \n",
        "model.add(Dense(units=500))\n",
        "model.add(Dropout(0.5))\n",
        "       \n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "        \n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "#%%\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=200, batch_size=64, verbose=2)\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#%%\n",
        "#model evaluation\n",
        "val_loss, val_acc = model.evaluate(X_test, Y_test)\n",
        "print(val_loss)\n",
        "print(val_acc)\n",
        "\n",
        "\n",
        "#%%\n",
        "# Visualizing the intermediate layer\n",
        "\n",
        "#\n",
        "from keras import backend as K\n",
        "test_image = X_test[0:1]\n",
        "print (test_image.shape)\n",
        "def get_featuremaps(model, layer_idx, X_batch):\n",
        "\tget_activations = K.function([model.layers[0].input, K.learning_phase()],[model.layers[layer_idx].output,])\n",
        "\tactivations = get_activations([X_batch,0])\n",
        "\treturn activations\n",
        "\n",
        "layer_num=0\n",
        "filter_num=0\n",
        "\n",
        "activations = get_featuremaps(model, int(layer_num),test_image)\n",
        "\n",
        "print (np.shape(activations))\n",
        "feature_maps = activations[0][0]      \n",
        "print (np.shape(feature_maps))\n",
        "\n",
        "if K.common.image_dim_ordering()=='th':\n",
        "\tfeature_maps=np.rollaxis((np.rollaxis(feature_maps,2,0)),2,0)\n",
        "print (feature_maps.shape)\n",
        "\n",
        "fig=plt.figure(figsize=(16,16))\n",
        "plt.imshow(feature_maps[:,:,filter_num],cmap='gray')\n",
        "# plt.savefig(\"featuremaps-layer-{}\".format(layer_num) + \"-filternum-{}\".format(filter_num)+'.bmp')\n",
        "\n",
        "num_of_featuremaps=feature_maps.shape[2]\n",
        "fig=plt.figure(figsize=(16,16))\t\n",
        "plt.title(\"featuremaps-layer-{}\".format(layer_num))\n",
        "subplot_num=int(np.ceil(np.sqrt(num_of_featuremaps)))\n",
        "for i in range(int(num_of_featuremaps)):\n",
        "\tax = fig.add_subplot(subplot_num, subplot_num, i+1)\n",
        "\t#ax.imshow(output_image[0,:,:,i],interpolation='nearest' ) #to see the first filter\n",
        "\tax.imshow(feature_maps[:,:,i],cmap='gray')\n",
        "\tplt.xticks([])\n",
        "\tplt.yticks([])\n",
        "\tplt.tight_layout()\n",
        "plt.show()\n",
        "# fig.savefig(\"featuremaps-layer-{}\".format(layer_num) + '.bmp')\n",
        "\n",
        "\n",
        "\n",
        "# Printing the confusion matrix\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "import itertools\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "print(Y_pred)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print(y_pred)\n",
        "#y_pred = model.predict_classes(X_test)\n",
        "#print(y_pred)\n",
        "#trget_names = ['class 0(cats)', 'class 1(Dogs)', 'class 2(Horses)','class 3(Humans)']\n",
        "\t\t\t\t\t\n",
        "# int(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=CATEGORIES)\n",
        "print(classification_report(np.argmax(Y_test, axis=1), y_pred, target_names=CATEGORIES))\n",
        "\n",
        "print(confusion_matrix(np.argmax(Y_test,axis=1), y_pred))\n",
        "\n",
        "\n",
        "# Plotting the confusion matrix\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Compute confusion matrix\n",
        "cnf_matrix = (confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
        "\n",
        "print(\"confusion matrix:\\n\", cnf_matrix) \n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()\n",
        "#save the model\n",
        "model.save('GujaratiOCRModel')\n",
        "#load saved model\n",
        "new_model = tf.keras.models.load_model('GujaratiOCRModel')\n",
        "\n",
        "#predict image on test data\n",
        "predictions = new_model.predict(X_test)\n",
        "\n",
        "print(CATEGORIES[np.argmax(predictions[160])])\n",
        "\n",
        "img = cv2.resize(X_test[160], (28,28))\n",
        "\n",
        "plt.imshow(img)\n",
        "\n",
        "#%%\n",
        "np.argmax(Y_test, axis=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n",
            "351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 350.89it/s]\n",
            "100%|██████████| 64/64 [00:12<00:00,  5.33it/s]\n",
            "100%|██████████| 48/48 [00:12<00:00,  3.87it/s]\n",
            "100%|██████████| 48/48 [00:11<00:00,  4.11it/s]\n",
            "100%|██████████| 75/75 [00:17<00:00,  4.39it/s]\n",
            "100%|██████████| 72/72 [00:15<00:00,  4.57it/s]\n",
            "100%|██████████| 45/45 [00:09<00:00,  4.80it/s]\n",
            "100%|██████████| 58/58 [00:13<00:00,  4.42it/s]\n",
            "100%|██████████| 60/60 [00:14<00:00,  4.26it/s]\n",
            "100%|██████████| 56/56 [00:12<00:00,  4.41it/s]\n",
            "100%|██████████| 140/140 [00:32<00:00,  4.29it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.13it/s]\n",
            "100%|██████████| 150/150 [00:34<00:00,  4.34it/s]\n",
            "100%|██████████| 150/150 [00:34<00:00,  4.38it/s]\n",
            "100%|██████████| 150/150 [00:32<00:00,  4.57it/s]\n",
            "100%|██████████| 150/150 [00:34<00:00,  4.31it/s]\n",
            "100%|██████████| 150/150 [00:35<00:00,  4.28it/s]\n",
            "100%|██████████| 153/153 [00:36<00:00,  4.24it/s]\n",
            "100%|██████████| 26/26 [00:06<00:00,  4.14it/s]\n",
            "100%|██████████| 159/159 [00:37<00:00,  4.29it/s]\n",
            "100%|██████████| 160/160 [00:36<00:00,  4.34it/s]\n",
            "100%|██████████| 170/170 [00:38<00:00,  4.40it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  3.75it/s]\n",
            "100%|██████████| 170/170 [00:39<00:00,  4.28it/s]\n",
            "100%|██████████| 16/16 [00:04<00:00,  3.92it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.29it/s]\n",
            "100%|██████████| 170/170 [00:37<00:00,  4.48it/s]\n",
            "100%|██████████| 102/102 [00:24<00:00,  4.24it/s]\n",
            "100%|██████████| 46/46 [00:10<00:00,  4.24it/s]\n",
            "100%|██████████| 57/57 [00:13<00:00,  4.21it/s]\n",
            "100%|██████████| 14/14 [00:03<00:00,  4.29it/s]\n",
            "100%|██████████| 47/47 [00:10<00:00,  4.37it/s]\n",
            "100%|██████████| 26/26 [00:05<00:00,  4.53it/s]\n",
            "100%|██████████| 38/38 [00:08<00:00,  4.35it/s]\n",
            "100%|██████████| 30/30 [00:06<00:00,  4.62it/s]\n",
            "100%|██████████| 20/20 [00:04<00:00,  4.45it/s]\n",
            "100%|██████████| 80/80 [00:18<00:00,  4.29it/s]\n",
            "100%|██████████| 70/70 [00:16<00:00,  4.20it/s]\n",
            "100%|██████████| 75/75 [00:17<00:00,  4.26it/s]\n",
            "100%|██████████| 47/47 [00:10<00:00,  4.55it/s]\n",
            "100%|██████████| 59/59 [00:13<00:00,  4.41it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.85it/s]\n",
            "100%|██████████| 18/18 [00:04<00:00,  4.12it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  5.09it/s]\n",
            "100%|██████████| 13/13 [00:02<00:00,  4.34it/s]\n",
            "100%|██████████| 190/190 [00:43<00:00,  4.35it/s]\n",
            "100%|██████████| 84/84 [00:17<00:00,  4.86it/s]\n",
            "100%|██████████| 82/82 [00:18<00:00,  4.50it/s]\n",
            "100%|██████████| 45/45 [00:10<00:00,  4.43it/s]\n",
            "100%|██████████| 57/57 [00:12<00:00,  4.66it/s]\n",
            "100%|██████████| 10/10 [00:01<00:00,  5.02it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.10it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.35it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.99it/s]\n",
            "100%|██████████| 17/17 [00:03<00:00,  4.59it/s]\n",
            "100%|██████████| 200/200 [00:45<00:00,  4.41it/s]\n",
            "100%|██████████| 85/85 [00:18<00:00,  4.57it/s]\n",
            "100%|██████████| 82/82 [00:18<00:00,  4.41it/s]\n",
            "100%|██████████| 42/42 [00:09<00:00,  4.35it/s]\n",
            "100%|██████████| 60/60 [00:13<00:00,  4.51it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.50it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.06it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.38it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.15it/s]\n",
            "100%|██████████| 17/17 [00:04<00:00,  4.04it/s]\n",
            "100%|██████████| 210/210 [00:48<00:00,  4.35it/s]\n",
            "100%|██████████| 77/77 [00:16<00:00,  4.72it/s]\n",
            "100%|██████████| 75/75 [00:17<00:00,  4.26it/s]\n",
            "100%|██████████| 42/42 [00:09<00:00,  4.45it/s]\n",
            "100%|██████████| 60/60 [00:12<00:00,  4.67it/s]\n",
            "100%|██████████| 10/10 [00:02<00:00,  4.51it/s]\n",
            "100%|██████████| 22/22 [00:04<00:00,  5.04it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.36it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.52it/s]\n",
            "100%|██████████| 18/18 [00:04<00:00,  4.29it/s]\n",
            "100%|██████████| 220/220 [00:49<00:00,  4.44it/s]\n",
            "100%|██████████| 73/73 [00:15<00:00,  4.70it/s]\n",
            "100%|██████████| 81/81 [00:18<00:00,  4.43it/s]\n",
            "100%|██████████| 39/39 [00:08<00:00,  4.56it/s]\n",
            "100%|██████████| 64/64 [00:14<00:00,  4.31it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  5.12it/s]\n",
            "100%|██████████| 24/24 [00:04<00:00,  4.93it/s]\n",
            "100%|██████████| 34/34 [00:07<00:00,  4.75it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.11it/s]\n",
            "100%|██████████| 16/16 [00:03<00:00,  4.35it/s]\n",
            "100%|██████████| 230/230 [00:55<00:00,  4.15it/s]\n",
            "100%|██████████| 70/70 [00:16<00:00,  4.30it/s]\n",
            "100%|██████████| 76/76 [00:18<00:00,  4.04it/s]\n",
            "100%|██████████| 46/46 [00:10<00:00,  4.27it/s]\n",
            "100%|██████████| 57/57 [00:13<00:00,  4.38it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.05it/s]\n",
            "100%|██████████| 23/23 [00:04<00:00,  4.70it/s]\n",
            "100%|██████████| 35/35 [00:07<00:00,  4.50it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.99it/s]\n",
            "100%|██████████| 240/240 [00:53<00:00,  4.45it/s]\n",
            "100%|██████████| 73/73 [00:15<00:00,  4.64it/s]\n",
            "100%|██████████| 83/83 [00:18<00:00,  4.42it/s]\n",
            "100%|██████████| 35/35 [00:07<00:00,  4.66it/s]\n",
            "100%|██████████| 60/60 [00:13<00:00,  4.34it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  3.93it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.16it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.33it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.15it/s]\n",
            "100%|██████████| 77/77 [00:15<00:00,  4.90it/s]\n",
            "100%|██████████| 79/79 [00:18<00:00,  4.24it/s]\n",
            "100%|██████████| 85/85 [00:19<00:00,  4.36it/s]\n",
            "100%|██████████| 48/48 [00:10<00:00,  4.44it/s]\n",
            "100%|██████████| 58/58 [00:12<00:00,  4.58it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.61it/s]\n",
            "100%|██████████| 23/23 [00:05<00:00,  3.90it/s]\n",
            "100%|██████████| 35/35 [00:07<00:00,  4.71it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.09it/s]\n",
            "100%|██████████| 260/260 [00:59<00:00,  4.37it/s]\n",
            "100%|██████████| 72/72 [00:15<00:00,  4.60it/s]\n",
            "100%|██████████| 81/81 [00:18<00:00,  4.29it/s]\n",
            "100%|██████████| 45/45 [00:09<00:00,  4.67it/s]\n",
            "100%|██████████| 60/60 [00:13<00:00,  4.29it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  5.12it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.49it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.65it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.64it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00,  6.26it/s]\n",
            "100%|██████████| 270/270 [01:03<00:00,  4.28it/s]\n",
            "100%|██████████| 73/73 [00:16<00:00,  4.31it/s]\n",
            "100%|██████████| 81/81 [00:17<00:00,  4.66it/s]\n",
            "100%|██████████| 48/48 [00:11<00:00,  4.32it/s]\n",
            "100%|██████████| 59/59 [00:13<00:00,  4.39it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.49it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.28it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  5.06it/s]\n",
            "100%|██████████| 10/10 [00:02<00:00,  4.32it/s]\n",
            "100%|██████████| 280/280 [01:03<00:00,  4.41it/s]\n",
            "100%|██████████| 76/76 [00:17<00:00,  4.24it/s]\n",
            "100%|██████████| 84/84 [00:18<00:00,  4.54it/s]\n",
            "100%|██████████| 47/47 [00:10<00:00,  4.32it/s]\n",
            "100%|██████████| 61/61 [00:12<00:00,  4.74it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.60it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.49it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.31it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.47it/s]\n",
            "100%|██████████| 280/280 [01:01<00:00,  4.55it/s]\n",
            "100%|██████████| 71/71 [00:16<00:00,  4.36it/s]\n",
            "100%|██████████| 87/87 [00:18<00:00,  4.72it/s]\n",
            "100%|██████████| 47/47 [00:10<00:00,  4.28it/s]\n",
            "100%|██████████| 58/58 [00:12<00:00,  4.59it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.26it/s]\n",
            "100%|██████████| 24/24 [00:06<00:00,  3.93it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.05it/s]\n",
            "100%|██████████| 12/12 [00:03<00:00,  3.73it/s]\n",
            "100%|██████████| 290/290 [01:06<00:00,  4.36it/s]\n",
            "100%|██████████| 74/74 [00:16<00:00,  4.56it/s]\n",
            "100%|██████████| 85/85 [00:20<00:00,  4.16it/s]\n",
            "100%|██████████| 46/46 [00:10<00:00,  4.49it/s]\n",
            "100%|██████████| 60/60 [00:13<00:00,  4.61it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  5.35it/s]\n",
            "100%|██████████| 23/23 [00:05<00:00,  4.30it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.54it/s]\n",
            "100%|██████████| 12/12 [00:03<00:00,  3.64it/s]\n",
            "100%|██████████| 293/293 [01:07<00:00,  4.34it/s]\n",
            "100%|██████████| 72/72 [00:16<00:00,  4.26it/s]\n",
            "100%|██████████| 84/84 [00:20<00:00,  4.19it/s]\n",
            "100%|██████████| 48/48 [00:11<00:00,  4.24it/s]\n",
            "100%|██████████| 61/61 [00:14<00:00,  4.11it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.61it/s]\n",
            "100%|██████████| 23/23 [00:05<00:00,  4.51it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.20it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.36it/s]\n",
            "100%|██████████| 292/292 [01:07<00:00,  4.35it/s]\n",
            "100%|██████████| 70/70 [00:15<00:00,  4.41it/s]\n",
            "100%|██████████| 79/79 [00:17<00:00,  4.48it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.40it/s]\n",
            "100%|██████████| 59/59 [00:13<00:00,  4.47it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.67it/s]\n",
            "100%|██████████| 23/23 [00:04<00:00,  4.97it/s]\n",
            "100%|██████████| 34/34 [00:07<00:00,  4.47it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  5.02it/s]\n",
            "100%|██████████| 48/48 [00:11<00:00,  4.24it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.17it/s]\n",
            "100%|██████████| 24/24 [00:06<00:00,  3.83it/s]\n",
            "100%|██████████| 12/12 [00:03<00:00,  3.71it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.30it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.28it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.51it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.81it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.53it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.96it/s]\n",
            "100%|██████████| 290/290 [01:04<00:00,  4.47it/s]\n",
            "100%|██████████| 72/72 [00:16<00:00,  4.31it/s]\n",
            "100%|██████████| 82/82 [00:18<00:00,  4.50it/s]\n",
            "100%|██████████| 50/50 [00:10<00:00,  4.82it/s]\n",
            "100%|██████████| 61/61 [00:12<00:00,  4.72it/s]\n",
            "100%|██████████| 13/13 [00:03<00:00,  3.75it/s]\n",
            "100%|██████████| 23/23 [00:04<00:00,  4.67it/s]\n",
            "100%|██████████| 34/34 [00:07<00:00,  4.28it/s]\n",
            "100%|██████████| 12/12 [00:03<00:00,  3.57it/s]\n",
            "100%|██████████| 294/294 [01:07<00:00,  4.38it/s]\n",
            "100%|██████████| 72/72 [00:16<00:00,  4.43it/s]\n",
            "100%|██████████| 87/87 [00:20<00:00,  4.17it/s]\n",
            "100%|██████████| 48/48 [00:12<00:00,  3.99it/s]\n",
            "100%|██████████| 57/57 [00:12<00:00,  4.44it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.28it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.40it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.51it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.71it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.30it/s]\n",
            "100%|██████████| 292/292 [01:06<00:00,  4.41it/s]\n",
            "100%|██████████| 82/82 [00:18<00:00,  4.41it/s]\n",
            "100%|██████████| 92/92 [00:20<00:00,  4.53it/s]\n",
            "100%|██████████| 50/50 [00:11<00:00,  4.50it/s]\n",
            "100%|██████████| 63/63 [00:13<00:00,  4.54it/s]\n",
            "100%|██████████| 13/13 [00:03<00:00,  4.31it/s]\n",
            "100%|██████████| 27/27 [00:06<00:00,  4.30it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.89it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.45it/s]\n",
            "100%|██████████| 292/292 [01:06<00:00,  4.40it/s]\n",
            "100%|██████████| 73/73 [00:16<00:00,  4.32it/s]\n",
            "100%|██████████| 80/80 [00:17<00:00,  4.52it/s]\n",
            "100%|██████████| 48/48 [00:10<00:00,  4.49it/s]\n",
            "100%|██████████| 61/61 [00:12<00:00,  4.86it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.62it/s]\n",
            "100%|██████████| 26/26 [00:06<00:00,  4.16it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.70it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.64it/s]\n",
            "100%|██████████| 77/77 [00:16<00:00,  4.58it/s]\n",
            "100%|██████████| 67/67 [00:14<00:00,  4.51it/s]\n",
            "100%|██████████| 68/68 [00:15<00:00,  4.27it/s]\n",
            "100%|██████████| 54/54 [00:12<00:00,  4.39it/s]\n",
            "100%|██████████| 58/58 [00:12<00:00,  4.82it/s]\n",
            "100%|██████████| 16/16 [00:03<00:00,  4.72it/s]\n",
            "100%|██████████| 25/25 [00:05<00:00,  4.78it/s]\n",
            "100%|██████████| 36/36 [00:08<00:00,  4.35it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00,  5.81it/s]\n",
            "100%|██████████| 85/85 [00:19<00:00,  4.39it/s]\n",
            "100%|██████████| 72/72 [00:17<00:00,  4.21it/s]\n",
            "100%|██████████| 93/93 [00:20<00:00,  4.58it/s]\n",
            "100%|██████████| 47/47 [00:09<00:00,  4.92it/s]\n",
            "100%|██████████| 58/58 [00:12<00:00,  4.55it/s]\n",
            "100%|██████████| 10/10 [00:02<00:00,  4.28it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.47it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.72it/s]\n",
            "100%|██████████| 13/13 [00:03<00:00,  4.26it/s]\n",
            "100%|██████████| 77/77 [00:16<00:00,  4.70it/s]\n",
            "100%|██████████| 73/73 [00:14<00:00,  4.95it/s]\n",
            "100%|██████████| 85/85 [00:18<00:00,  4.57it/s]\n",
            "100%|██████████| 44/44 [00:10<00:00,  4.30it/s]\n",
            "100%|██████████| 60/60 [00:13<00:00,  4.31it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.50it/s]\n",
            "100%|██████████| 23/23 [00:05<00:00,  4.32it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.55it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.80it/s]\n",
            "100%|██████████| 77/77 [00:17<00:00,  4.38it/s]\n",
            "100%|██████████| 73/73 [00:16<00:00,  4.30it/s]\n",
            "100%|██████████| 80/80 [00:17<00:00,  4.54it/s]\n",
            "100%|██████████| 45/45 [00:09<00:00,  4.53it/s]\n",
            "100%|██████████| 58/58 [00:12<00:00,  4.70it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  5.31it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.38it/s]\n",
            "100%|██████████| 35/35 [00:06<00:00,  5.23it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.68it/s]\n",
            "100%|██████████| 79/79 [00:16<00:00,  4.78it/s]\n",
            "100%|██████████| 74/74 [00:15<00:00,  4.70it/s]\n",
            "100%|██████████| 84/84 [00:17<00:00,  4.67it/s]\n",
            "100%|██████████| 55/55 [00:12<00:00,  4.58it/s]\n",
            "100%|██████████| 58/58 [00:11<00:00,  4.96it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.87it/s]\n",
            "100%|██████████| 20/20 [00:04<00:00,  4.99it/s]\n",
            "100%|██████████| 34/34 [00:07<00:00,  4.29it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.81it/s]\n",
            "100%|██████████| 75/75 [00:15<00:00,  4.74it/s]\n",
            "100%|██████████| 81/81 [00:17<00:00,  4.62it/s]\n",
            "100%|██████████| 94/94 [00:20<00:00,  4.55it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.76it/s]\n",
            "100%|██████████| 50/50 [00:10<00:00,  4.67it/s]\n",
            "100%|██████████| 8/8 [00:01<00:00,  4.34it/s]\n",
            "100%|██████████| 18/18 [00:03<00:00,  4.98it/s]\n",
            "100%|██████████| 33/33 [00:06<00:00,  4.76it/s]\n",
            "100%|██████████| 22/22 [00:04<00:00,  4.54it/s]\n",
            "100%|██████████| 77/77 [00:16<00:00,  4.57it/s]\n",
            "100%|██████████| 71/71 [00:14<00:00,  4.99it/s]\n",
            "100%|██████████| 82/82 [00:18<00:00,  4.47it/s]\n",
            "100%|██████████| 46/46 [00:10<00:00,  4.50it/s]\n",
            "100%|██████████| 58/58 [00:12<00:00,  4.55it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.59it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.29it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.71it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.93it/s]\n",
            "100%|██████████| 75/75 [00:16<00:00,  4.58it/s]\n",
            "100%|██████████| 73/73 [00:15<00:00,  4.66it/s]\n",
            "100%|██████████| 95/95 [00:20<00:00,  4.52it/s]\n",
            "100%|██████████| 57/57 [00:11<00:00,  5.07it/s]\n",
            "100%|██████████| 57/57 [00:11<00:00,  4.96it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.11it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.36it/s]\n",
            "100%|██████████| 35/35 [00:07<00:00,  4.55it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.18it/s]\n",
            "100%|██████████| 75/75 [00:15<00:00,  4.91it/s]\n",
            "100%|██████████| 73/73 [00:15<00:00,  4.72it/s]\n",
            "100%|██████████| 80/80 [00:17<00:00,  4.50it/s]\n",
            "100%|██████████| 47/47 [00:09<00:00,  4.80it/s]\n",
            "100%|██████████| 60/60 [00:13<00:00,  4.47it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.29it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.76it/s]\n",
            "100%|██████████| 35/35 [00:08<00:00,  4.37it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.35it/s]\n",
            "100%|██████████| 74/74 [00:17<00:00,  4.29it/s]\n",
            "100%|██████████| 80/80 [00:15<00:00,  5.03it/s]\n",
            "100%|██████████| 85/85 [00:17<00:00,  4.77it/s]\n",
            "100%|██████████| 48/48 [00:10<00:00,  4.58it/s]\n",
            "100%|██████████| 59/59 [00:12<00:00,  4.78it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.63it/s]\n",
            "100%|██████████| 23/23 [00:04<00:00,  4.75it/s]\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.64it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.68it/s]\n",
            "100%|██████████| 76/76 [00:15<00:00,  4.77it/s]\n",
            "100%|██████████| 76/76 [00:15<00:00,  4.85it/s]\n",
            "100%|██████████| 83/83 [00:19<00:00,  4.32it/s]\n",
            "100%|██████████| 48/48 [00:10<00:00,  4.58it/s]\n",
            "100%|██████████| 59/59 [00:12<00:00,  4.56it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.49it/s]\n",
            "100%|██████████| 28/28 [00:06<00:00,  4.64it/s]\n",
            "100%|██████████| 35/35 [00:07<00:00,  4.54it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.89it/s]\n",
            "100%|██████████| 11/11 [00:02<00:00,  4.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
            "100%|██████████| 84/84 [00:17<00:00,  4.89it/s]\n",
            "100%|██████████| 73/73 [00:16<00:00,  4.45it/s]\n",
            "100%|██████████| 80/80 [00:17<00:00,  4.56it/s]\n",
            "100%|██████████| 47/47 [00:09<00:00,  4.91it/s]\n",
            "100%|██████████| 49/49 [00:10<00:00,  4.67it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  5.18it/s]\n",
            "100%|██████████| 25/25 [00:04<00:00,  5.24it/s]\n",
            "100%|██████████| 37/37 [00:06<00:00,  5.37it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  5.30it/s]\n",
            "100%|██████████| 77/77 [00:17<00:00,  4.53it/s]\n",
            "100%|██████████| 72/72 [00:15<00:00,  4.56it/s]\n",
            "100%|██████████| 85/85 [00:18<00:00,  4.63it/s]\n",
            "100%|██████████| 47/47 [00:09<00:00,  4.83it/s]\n",
            "100%|██████████| 62/62 [00:13<00:00,  4.58it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.89it/s]\n",
            "100%|██████████| 24/24 [00:05<00:00,  4.56it/s]\n",
            "100%|██████████| 35/35 [00:08<00:00,  4.27it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.34it/s]\n",
            "100%|██████████| 74/74 [00:16<00:00,  4.37it/s]\n",
            "100%|██████████| 70/70 [00:15<00:00,  4.50it/s]\n",
            "100%|██████████| 61/61 [00:14<00:00,  4.26it/s]\n",
            "100%|██████████| 48/48 [00:09<00:00,  4.87it/s]\n",
            "100%|██████████| 57/57 [00:11<00:00,  4.87it/s]\n",
            "100%|██████████| 9/9 [00:02<00:00,  4.42it/s]\n",
            "100%|██████████| 16/16 [00:03<00:00,  4.69it/s]\n",
            "100%|██████████| 34/34 [00:07<00:00,  4.76it/s]\n",
            "100%|██████████| 10/10 [00:01<00:00,  5.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "149\n",
            "234\n",
            "344\n",
            "95\n",
            "338\n",
            "86\n",
            "52\n",
            "214\n",
            "91\n",
            "160\n",
            "234\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 24, 24, 16)        416       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 22, 22, 16)        2320      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 22, 22, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 10, 10, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 32)          9248      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 2, 2, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 1, 1, 64)          8256      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 1, 1, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               32500     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 351)               175851    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 233,231\n",
            "Trainable params: 233,231\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "252/252 - 18s - loss: 5.4921 - accuracy: 0.0138 - val_loss: 5.1658 - val_accuracy: 0.0288 - 18s/epoch - 73ms/step\n",
            "Epoch 2/200\n",
            "252/252 - 17s - loss: 4.9022 - accuracy: 0.0400 - val_loss: 4.6813 - val_accuracy: 0.0733 - 17s/epoch - 68ms/step\n",
            "Epoch 3/200\n",
            "252/252 - 17s - loss: 4.3958 - accuracy: 0.0768 - val_loss: 4.1838 - val_accuracy: 0.1188 - 17s/epoch - 68ms/step\n",
            "Epoch 4/200\n",
            "252/252 - 17s - loss: 4.0570 - accuracy: 0.1106 - val_loss: 3.8073 - val_accuracy: 0.1754 - 17s/epoch - 69ms/step\n",
            "Epoch 5/200\n",
            "252/252 - 17s - loss: 3.7723 - accuracy: 0.1388 - val_loss: 3.5808 - val_accuracy: 0.2227 - 17s/epoch - 69ms/step\n",
            "Epoch 6/200\n",
            "252/252 - 17s - loss: 3.5544 - accuracy: 0.1734 - val_loss: 3.3411 - val_accuracy: 0.2719 - 17s/epoch - 69ms/step\n",
            "Epoch 7/200\n",
            "252/252 - 17s - loss: 3.3989 - accuracy: 0.1955 - val_loss: 3.1581 - val_accuracy: 0.2746 - 17s/epoch - 69ms/step\n",
            "Epoch 8/200\n",
            "252/252 - 17s - loss: 3.2503 - accuracy: 0.2183 - val_loss: 3.0208 - val_accuracy: 0.3077 - 17s/epoch - 68ms/step\n",
            "Epoch 9/200\n",
            "252/252 - 17s - loss: 3.1489 - accuracy: 0.2322 - val_loss: 2.8597 - val_accuracy: 0.3367 - 17s/epoch - 69ms/step\n",
            "Epoch 10/200\n",
            "252/252 - 17s - loss: 3.0591 - accuracy: 0.2444 - val_loss: 2.8030 - val_accuracy: 0.3422 - 17s/epoch - 68ms/step\n",
            "Epoch 11/200\n",
            "252/252 - 17s - loss: 2.9701 - accuracy: 0.2604 - val_loss: 2.7542 - val_accuracy: 0.3586 - 17s/epoch - 68ms/step\n",
            "Epoch 12/200\n",
            "252/252 - 17s - loss: 2.9170 - accuracy: 0.2708 - val_loss: 2.6754 - val_accuracy: 0.3817 - 17s/epoch - 68ms/step\n",
            "Epoch 13/200\n",
            "252/252 - 17s - loss: 2.8471 - accuracy: 0.2774 - val_loss: 2.5365 - val_accuracy: 0.3954 - 17s/epoch - 68ms/step\n",
            "Epoch 14/200\n",
            "252/252 - 17s - loss: 2.8021 - accuracy: 0.2921 - val_loss: 2.5347 - val_accuracy: 0.4078 - 17s/epoch - 68ms/step\n",
            "Epoch 15/200\n",
            "252/252 - 17s - loss: 2.7505 - accuracy: 0.2978 - val_loss: 2.4634 - val_accuracy: 0.4118 - 17s/epoch - 68ms/step\n",
            "Epoch 16/200\n",
            "252/252 - 17s - loss: 2.7092 - accuracy: 0.3005 - val_loss: 2.4336 - val_accuracy: 0.4336 - 17s/epoch - 68ms/step\n",
            "Epoch 17/200\n",
            "252/252 - 17s - loss: 2.6686 - accuracy: 0.3143 - val_loss: 2.4504 - val_accuracy: 0.4200 - 17s/epoch - 68ms/step\n",
            "Epoch 18/200\n",
            "252/252 - 17s - loss: 2.6351 - accuracy: 0.3205 - val_loss: 2.3504 - val_accuracy: 0.4341 - 17s/epoch - 68ms/step\n",
            "Epoch 19/200\n",
            "252/252 - 17s - loss: 2.5883 - accuracy: 0.3263 - val_loss: 2.2734 - val_accuracy: 0.4523 - 17s/epoch - 68ms/step\n",
            "Epoch 20/200\n",
            "252/252 - 17s - loss: 2.5477 - accuracy: 0.3342 - val_loss: 2.2450 - val_accuracy: 0.4637 - 17s/epoch - 69ms/step\n",
            "Epoch 21/200\n",
            "252/252 - 17s - loss: 2.5229 - accuracy: 0.3388 - val_loss: 2.2030 - val_accuracy: 0.4719 - 17s/epoch - 69ms/step\n",
            "Epoch 22/200\n",
            "252/252 - 18s - loss: 2.5025 - accuracy: 0.3425 - val_loss: 2.1618 - val_accuracy: 0.4759 - 18s/epoch - 70ms/step\n",
            "Epoch 23/200\n",
            "252/252 - 18s - loss: 2.4522 - accuracy: 0.3545 - val_loss: 2.1605 - val_accuracy: 0.4704 - 18s/epoch - 70ms/step\n",
            "Epoch 24/200\n",
            "252/252 - 18s - loss: 2.4284 - accuracy: 0.3550 - val_loss: 2.1591 - val_accuracy: 0.4722 - 18s/epoch - 70ms/step\n",
            "Epoch 25/200\n",
            "252/252 - 18s - loss: 2.4025 - accuracy: 0.3657 - val_loss: 2.1428 - val_accuracy: 0.4791 - 18s/epoch - 70ms/step\n",
            "Epoch 26/200\n",
            "252/252 - 18s - loss: 2.3838 - accuracy: 0.3689 - val_loss: 2.0522 - val_accuracy: 0.4935 - 18s/epoch - 70ms/step\n",
            "Epoch 27/200\n",
            "252/252 - 18s - loss: 2.3416 - accuracy: 0.3741 - val_loss: 2.0854 - val_accuracy: 0.4925 - 18s/epoch - 70ms/step\n",
            "Epoch 28/200\n",
            "252/252 - 18s - loss: 2.3329 - accuracy: 0.3732 - val_loss: 2.0411 - val_accuracy: 0.4985 - 18s/epoch - 70ms/step\n",
            "Epoch 29/200\n",
            "252/252 - 18s - loss: 2.3039 - accuracy: 0.3872 - val_loss: 1.9513 - val_accuracy: 0.5102 - 18s/epoch - 71ms/step\n",
            "Epoch 30/200\n",
            "252/252 - 18s - loss: 2.2835 - accuracy: 0.3863 - val_loss: 1.9807 - val_accuracy: 0.5077 - 18s/epoch - 70ms/step\n",
            "Epoch 31/200\n",
            "252/252 - 18s - loss: 2.2724 - accuracy: 0.3911 - val_loss: 1.9543 - val_accuracy: 0.5199 - 18s/epoch - 70ms/step\n",
            "Epoch 32/200\n",
            "252/252 - 18s - loss: 2.2399 - accuracy: 0.3924 - val_loss: 1.9726 - val_accuracy: 0.5092 - 18s/epoch - 71ms/step\n",
            "Epoch 33/200\n",
            "252/252 - 18s - loss: 2.2286 - accuracy: 0.3985 - val_loss: 1.9090 - val_accuracy: 0.5149 - 18s/epoch - 71ms/step\n",
            "Epoch 34/200\n",
            "252/252 - 18s - loss: 2.2169 - accuracy: 0.4002 - val_loss: 1.9282 - val_accuracy: 0.5191 - 18s/epoch - 70ms/step\n",
            "Epoch 35/200\n",
            "252/252 - 18s - loss: 2.1945 - accuracy: 0.4064 - val_loss: 1.8841 - val_accuracy: 0.5368 - 18s/epoch - 71ms/step\n",
            "Epoch 36/200\n",
            "252/252 - 18s - loss: 2.1819 - accuracy: 0.4061 - val_loss: 1.8633 - val_accuracy: 0.5308 - 18s/epoch - 72ms/step\n",
            "Epoch 37/200\n",
            "252/252 - 18s - loss: 2.1627 - accuracy: 0.4129 - val_loss: 1.8244 - val_accuracy: 0.5400 - 18s/epoch - 73ms/step\n",
            "Epoch 38/200\n",
            "252/252 - 18s - loss: 2.1418 - accuracy: 0.4165 - val_loss: 1.8170 - val_accuracy: 0.5490 - 18s/epoch - 71ms/step\n",
            "Epoch 39/200\n",
            "252/252 - 18s - loss: 2.1277 - accuracy: 0.4188 - val_loss: 1.7878 - val_accuracy: 0.5460 - 18s/epoch - 70ms/step\n",
            "Epoch 40/200\n",
            "252/252 - 18s - loss: 2.1273 - accuracy: 0.4251 - val_loss: 1.8451 - val_accuracy: 0.5425 - 18s/epoch - 71ms/step\n",
            "Epoch 41/200\n",
            "252/252 - 18s - loss: 2.1163 - accuracy: 0.4249 - val_loss: 1.7855 - val_accuracy: 0.5455 - 18s/epoch - 71ms/step\n",
            "Epoch 42/200\n",
            "252/252 - 18s - loss: 2.0871 - accuracy: 0.4280 - val_loss: 1.8138 - val_accuracy: 0.5437 - 18s/epoch - 72ms/step\n",
            "Epoch 43/200\n",
            "252/252 - 18s - loss: 2.0879 - accuracy: 0.4293 - val_loss: 1.7884 - val_accuracy: 0.5462 - 18s/epoch - 70ms/step\n",
            "Epoch 44/200\n",
            "252/252 - 18s - loss: 2.0785 - accuracy: 0.4329 - val_loss: 1.7530 - val_accuracy: 0.5554 - 18s/epoch - 70ms/step\n",
            "Epoch 45/200\n",
            "252/252 - 18s - loss: 2.0607 - accuracy: 0.4377 - val_loss: 1.7115 - val_accuracy: 0.5664 - 18s/epoch - 72ms/step\n",
            "Epoch 46/200\n",
            "252/252 - 18s - loss: 2.0541 - accuracy: 0.4401 - val_loss: 1.7289 - val_accuracy: 0.5639 - 18s/epoch - 72ms/step\n",
            "Epoch 47/200\n",
            "252/252 - 18s - loss: 2.0409 - accuracy: 0.4396 - val_loss: 1.6849 - val_accuracy: 0.5741 - 18s/epoch - 71ms/step\n",
            "Epoch 48/200\n",
            "252/252 - 18s - loss: 2.0309 - accuracy: 0.4413 - val_loss: 1.7677 - val_accuracy: 0.5485 - 18s/epoch - 71ms/step\n",
            "Epoch 49/200\n",
            "252/252 - 18s - loss: 2.0198 - accuracy: 0.4479 - val_loss: 1.6747 - val_accuracy: 0.5743 - 18s/epoch - 70ms/step\n",
            "Epoch 50/200\n",
            "252/252 - 18s - loss: 2.0109 - accuracy: 0.4482 - val_loss: 1.6915 - val_accuracy: 0.5666 - 18s/epoch - 71ms/step\n",
            "Epoch 51/200\n",
            "252/252 - 18s - loss: 2.0172 - accuracy: 0.4464 - val_loss: 1.7001 - val_accuracy: 0.5847 - 18s/epoch - 70ms/step\n",
            "Epoch 52/200\n",
            "252/252 - 18s - loss: 1.9764 - accuracy: 0.4521 - val_loss: 1.7094 - val_accuracy: 0.5644 - 18s/epoch - 71ms/step\n",
            "Epoch 53/200\n",
            "252/252 - 18s - loss: 1.9764 - accuracy: 0.4593 - val_loss: 1.7781 - val_accuracy: 0.5504 - 18s/epoch - 70ms/step\n",
            "Epoch 54/200\n",
            "252/252 - 18s - loss: 1.9869 - accuracy: 0.4488 - val_loss: 1.7143 - val_accuracy: 0.5701 - 18s/epoch - 70ms/step\n",
            "Epoch 55/200\n",
            "252/252 - 18s - loss: 1.9580 - accuracy: 0.4596 - val_loss: 1.6867 - val_accuracy: 0.5676 - 18s/epoch - 71ms/step\n",
            "Epoch 56/200\n",
            "252/252 - 18s - loss: 1.9793 - accuracy: 0.4555 - val_loss: 1.6068 - val_accuracy: 0.5835 - 18s/epoch - 70ms/step\n",
            "Epoch 57/200\n",
            "252/252 - 17s - loss: 1.9491 - accuracy: 0.4666 - val_loss: 1.6455 - val_accuracy: 0.5825 - 17s/epoch - 69ms/step\n",
            "Epoch 58/200\n",
            "252/252 - 18s - loss: 1.9535 - accuracy: 0.4655 - val_loss: 1.6134 - val_accuracy: 0.5845 - 18s/epoch - 70ms/step\n",
            "Epoch 59/200\n",
            "252/252 - 18s - loss: 1.9277 - accuracy: 0.4626 - val_loss: 1.5826 - val_accuracy: 0.5892 - 18s/epoch - 70ms/step\n",
            "Epoch 60/200\n",
            "252/252 - 18s - loss: 1.9611 - accuracy: 0.4563 - val_loss: 1.6456 - val_accuracy: 0.5733 - 18s/epoch - 71ms/step\n",
            "Epoch 61/200\n",
            "252/252 - 18s - loss: 1.9224 - accuracy: 0.4675 - val_loss: 1.6109 - val_accuracy: 0.5862 - 18s/epoch - 72ms/step\n",
            "Epoch 62/200\n",
            "252/252 - 18s - loss: 1.9072 - accuracy: 0.4737 - val_loss: 1.5857 - val_accuracy: 0.5882 - 18s/epoch - 71ms/step\n",
            "Epoch 63/200\n",
            "252/252 - 18s - loss: 1.9221 - accuracy: 0.4690 - val_loss: 1.6644 - val_accuracy: 0.5818 - 18s/epoch - 72ms/step\n",
            "Epoch 64/200\n",
            "252/252 - 18s - loss: 1.9147 - accuracy: 0.4694 - val_loss: 1.5820 - val_accuracy: 0.5850 - 18s/epoch - 72ms/step\n",
            "Epoch 65/200\n",
            "252/252 - 18s - loss: 1.9317 - accuracy: 0.4704 - val_loss: 1.5946 - val_accuracy: 0.5932 - 18s/epoch - 71ms/step\n",
            "Epoch 66/200\n",
            "252/252 - 18s - loss: 1.8835 - accuracy: 0.4790 - val_loss: 1.5891 - val_accuracy: 0.5900 - 18s/epoch - 72ms/step\n",
            "Epoch 67/200\n",
            "252/252 - 18s - loss: 1.8948 - accuracy: 0.4723 - val_loss: 1.5814 - val_accuracy: 0.6019 - 18s/epoch - 72ms/step\n",
            "Epoch 68/200\n",
            "252/252 - 18s - loss: 1.8705 - accuracy: 0.4762 - val_loss: 1.5794 - val_accuracy: 0.6029 - 18s/epoch - 73ms/step\n",
            "Epoch 69/200\n",
            "252/252 - 18s - loss: 1.8843 - accuracy: 0.4778 - val_loss: 1.5712 - val_accuracy: 0.5875 - 18s/epoch - 72ms/step\n",
            "Epoch 70/200\n",
            "252/252 - 18s - loss: 1.8947 - accuracy: 0.4774 - val_loss: 1.5581 - val_accuracy: 0.5949 - 18s/epoch - 72ms/step\n",
            "Epoch 71/200\n",
            "252/252 - 18s - loss: 1.8659 - accuracy: 0.4795 - val_loss: 1.5685 - val_accuracy: 0.5890 - 18s/epoch - 71ms/step\n",
            "Epoch 72/200\n",
            "252/252 - 18s - loss: 1.8643 - accuracy: 0.4782 - val_loss: 1.5506 - val_accuracy: 0.5917 - 18s/epoch - 70ms/step\n",
            "Epoch 73/200\n",
            "252/252 - 18s - loss: 1.8516 - accuracy: 0.4803 - val_loss: 1.5008 - val_accuracy: 0.6081 - 18s/epoch - 71ms/step\n",
            "Epoch 74/200\n",
            "252/252 - 18s - loss: 1.8697 - accuracy: 0.4805 - val_loss: 1.5830 - val_accuracy: 0.5867 - 18s/epoch - 70ms/step\n",
            "Epoch 75/200\n",
            "252/252 - 18s - loss: 1.8248 - accuracy: 0.4874 - val_loss: 1.5206 - val_accuracy: 0.6079 - 18s/epoch - 71ms/step\n",
            "Epoch 76/200\n",
            "252/252 - 18s - loss: 1.8478 - accuracy: 0.4885 - val_loss: 1.5364 - val_accuracy: 0.6029 - 18s/epoch - 70ms/step\n",
            "Epoch 77/200\n",
            "252/252 - 18s - loss: 1.8255 - accuracy: 0.4857 - val_loss: 1.5512 - val_accuracy: 0.6051 - 18s/epoch - 71ms/step\n",
            "Epoch 78/200\n",
            "252/252 - 18s - loss: 1.8362 - accuracy: 0.4923 - val_loss: 1.5233 - val_accuracy: 0.6071 - 18s/epoch - 73ms/step\n",
            "Epoch 79/200\n",
            "252/252 - 18s - loss: 1.8364 - accuracy: 0.4852 - val_loss: 1.5474 - val_accuracy: 0.6044 - 18s/epoch - 73ms/step\n",
            "Epoch 80/200\n",
            "252/252 - 18s - loss: 1.8353 - accuracy: 0.4915 - val_loss: 1.5125 - val_accuracy: 0.6069 - 18s/epoch - 72ms/step\n",
            "Epoch 81/200\n",
            "252/252 - 18s - loss: 1.8086 - accuracy: 0.4980 - val_loss: 1.5597 - val_accuracy: 0.5964 - 18s/epoch - 72ms/step\n",
            "Epoch 82/200\n",
            "252/252 - 18s - loss: 1.8259 - accuracy: 0.4906 - val_loss: 1.4857 - val_accuracy: 0.6126 - 18s/epoch - 72ms/step\n",
            "Epoch 83/200\n",
            "252/252 - 18s - loss: 1.8232 - accuracy: 0.4865 - val_loss: 1.4737 - val_accuracy: 0.6138 - 18s/epoch - 72ms/step\n",
            "Epoch 84/200\n",
            "252/252 - 18s - loss: 1.7980 - accuracy: 0.4900 - val_loss: 1.5905 - val_accuracy: 0.5875 - 18s/epoch - 73ms/step\n",
            "Epoch 85/200\n",
            "252/252 - 18s - loss: 1.8133 - accuracy: 0.4975 - val_loss: 1.5790 - val_accuracy: 0.5934 - 18s/epoch - 71ms/step\n",
            "Epoch 86/200\n",
            "252/252 - 18s - loss: 1.7907 - accuracy: 0.4991 - val_loss: 1.5403 - val_accuracy: 0.5912 - 18s/epoch - 72ms/step\n",
            "Epoch 87/200\n",
            "252/252 - 18s - loss: 1.7831 - accuracy: 0.5017 - val_loss: 1.4660 - val_accuracy: 0.6128 - 18s/epoch - 71ms/step\n",
            "Epoch 88/200\n",
            "252/252 - 18s - loss: 1.7763 - accuracy: 0.5025 - val_loss: 1.5190 - val_accuracy: 0.6083 - 18s/epoch - 70ms/step\n",
            "Epoch 89/200\n",
            "252/252 - 18s - loss: 1.7940 - accuracy: 0.5022 - val_loss: 1.4848 - val_accuracy: 0.6079 - 18s/epoch - 71ms/step\n",
            "Epoch 90/200\n",
            "252/252 - 18s - loss: 1.7882 - accuracy: 0.5006 - val_loss: 1.4529 - val_accuracy: 0.6240 - 18s/epoch - 70ms/step\n",
            "Epoch 91/200\n",
            "252/252 - 18s - loss: 1.7843 - accuracy: 0.4965 - val_loss: 1.4674 - val_accuracy: 0.6208 - 18s/epoch - 70ms/step\n",
            "Epoch 92/200\n",
            "252/252 - 18s - loss: 1.7787 - accuracy: 0.4996 - val_loss: 1.5009 - val_accuracy: 0.6178 - 18s/epoch - 70ms/step\n",
            "Epoch 93/200\n",
            "252/252 - 18s - loss: 1.7575 - accuracy: 0.5047 - val_loss: 1.4905 - val_accuracy: 0.6071 - 18s/epoch - 70ms/step\n",
            "Epoch 94/200\n",
            "252/252 - 18s - loss: 1.7718 - accuracy: 0.5044 - val_loss: 1.4414 - val_accuracy: 0.6098 - 18s/epoch - 70ms/step\n",
            "Epoch 95/200\n",
            "252/252 - 18s - loss: 1.7487 - accuracy: 0.5098 - val_loss: 1.4856 - val_accuracy: 0.5989 - 18s/epoch - 72ms/step\n",
            "Epoch 96/200\n",
            "252/252 - 18s - loss: 1.7689 - accuracy: 0.5049 - val_loss: 1.4526 - val_accuracy: 0.6203 - 18s/epoch - 71ms/step\n",
            "Epoch 97/200\n",
            "252/252 - 18s - loss: 1.7494 - accuracy: 0.5065 - val_loss: 1.4908 - val_accuracy: 0.6108 - 18s/epoch - 70ms/step\n",
            "Epoch 98/200\n",
            "252/252 - 18s - loss: 1.7732 - accuracy: 0.5036 - val_loss: 1.4640 - val_accuracy: 0.6098 - 18s/epoch - 71ms/step\n",
            "Epoch 99/200\n",
            "252/252 - 18s - loss: 1.7432 - accuracy: 0.5080 - val_loss: 1.4260 - val_accuracy: 0.6220 - 18s/epoch - 70ms/step\n",
            "Epoch 100/200\n",
            "252/252 - 18s - loss: 1.7397 - accuracy: 0.5082 - val_loss: 1.4564 - val_accuracy: 0.6203 - 18s/epoch - 71ms/step\n",
            "Epoch 101/200\n",
            "252/252 - 18s - loss: 1.7536 - accuracy: 0.5116 - val_loss: 1.4478 - val_accuracy: 0.6170 - 18s/epoch - 71ms/step\n",
            "Epoch 102/200\n",
            "252/252 - 18s - loss: 1.7292 - accuracy: 0.5125 - val_loss: 1.4276 - val_accuracy: 0.6238 - 18s/epoch - 70ms/step\n",
            "Epoch 103/200\n",
            "252/252 - 17s - loss: 1.7358 - accuracy: 0.5134 - val_loss: 1.4407 - val_accuracy: 0.6250 - 17s/epoch - 69ms/step\n",
            "Epoch 104/200\n",
            "252/252 - 18s - loss: 1.7256 - accuracy: 0.5084 - val_loss: 1.4263 - val_accuracy: 0.6267 - 18s/epoch - 70ms/step\n",
            "Epoch 105/200\n",
            "252/252 - 18s - loss: 1.7416 - accuracy: 0.5128 - val_loss: 1.4252 - val_accuracy: 0.6267 - 18s/epoch - 71ms/step\n",
            "Epoch 106/200\n",
            "252/252 - 18s - loss: 1.7403 - accuracy: 0.5087 - val_loss: 1.4377 - val_accuracy: 0.6170 - 18s/epoch - 72ms/step\n",
            "Epoch 107/200\n",
            "252/252 - 18s - loss: 1.6949 - accuracy: 0.5204 - val_loss: 1.4631 - val_accuracy: 0.6205 - 18s/epoch - 71ms/step\n",
            "Epoch 108/200\n",
            "252/252 - 18s - loss: 1.7247 - accuracy: 0.5154 - val_loss: 1.4038 - val_accuracy: 0.6342 - 18s/epoch - 71ms/step\n",
            "Epoch 109/200\n",
            "252/252 - 18s - loss: 1.7285 - accuracy: 0.5132 - val_loss: 1.4429 - val_accuracy: 0.6243 - 18s/epoch - 70ms/step\n",
            "Epoch 110/200\n",
            "252/252 - 18s - loss: 1.7244 - accuracy: 0.5127 - val_loss: 1.4031 - val_accuracy: 0.6305 - 18s/epoch - 71ms/step\n",
            "Epoch 111/200\n",
            "252/252 - 18s - loss: 1.7183 - accuracy: 0.5125 - val_loss: 1.4158 - val_accuracy: 0.6223 - 18s/epoch - 71ms/step\n",
            "Epoch 112/200\n",
            "252/252 - 18s - loss: 1.7190 - accuracy: 0.5158 - val_loss: 1.4785 - val_accuracy: 0.6106 - 18s/epoch - 72ms/step\n",
            "Epoch 113/200\n",
            "252/252 - 18s - loss: 1.7202 - accuracy: 0.5158 - val_loss: 1.4018 - val_accuracy: 0.6339 - 18s/epoch - 70ms/step\n",
            "Epoch 114/200\n",
            "252/252 - 18s - loss: 1.7237 - accuracy: 0.5117 - val_loss: 1.3992 - val_accuracy: 0.6352 - 18s/epoch - 71ms/step\n",
            "Epoch 115/200\n",
            "252/252 - 18s - loss: 1.7216 - accuracy: 0.5163 - val_loss: 1.4253 - val_accuracy: 0.6342 - 18s/epoch - 71ms/step\n",
            "Epoch 116/200\n",
            "252/252 - 18s - loss: 1.6893 - accuracy: 0.5251 - val_loss: 1.4474 - val_accuracy: 0.6064 - 18s/epoch - 71ms/step\n",
            "Epoch 117/200\n",
            "252/252 - 18s - loss: 1.6891 - accuracy: 0.5249 - val_loss: 1.3792 - val_accuracy: 0.6337 - 18s/epoch - 70ms/step\n",
            "Epoch 118/200\n",
            "252/252 - 18s - loss: 1.6918 - accuracy: 0.5202 - val_loss: 1.3972 - val_accuracy: 0.6404 - 18s/epoch - 71ms/step\n",
            "Epoch 119/200\n",
            "252/252 - 18s - loss: 1.6819 - accuracy: 0.5223 - val_loss: 1.4440 - val_accuracy: 0.6188 - 18s/epoch - 70ms/step\n",
            "Epoch 120/200\n",
            "252/252 - 17s - loss: 1.7130 - accuracy: 0.5136 - val_loss: 1.4098 - val_accuracy: 0.6265 - 17s/epoch - 69ms/step\n",
            "Epoch 121/200\n",
            "252/252 - 18s - loss: 1.6872 - accuracy: 0.5221 - val_loss: 1.3923 - val_accuracy: 0.6290 - 18s/epoch - 69ms/step\n",
            "Epoch 122/200\n",
            "252/252 - 18s - loss: 1.7069 - accuracy: 0.5175 - val_loss: 1.4009 - val_accuracy: 0.6277 - 18s/epoch - 70ms/step\n",
            "Epoch 123/200\n",
            "252/252 - 17s - loss: 1.6683 - accuracy: 0.5257 - val_loss: 1.3610 - val_accuracy: 0.6349 - 17s/epoch - 69ms/step\n",
            "Epoch 124/200\n",
            "252/252 - 18s - loss: 1.6785 - accuracy: 0.5233 - val_loss: 1.3857 - val_accuracy: 0.6394 - 18s/epoch - 70ms/step\n",
            "Epoch 125/200\n",
            "252/252 - 18s - loss: 1.6901 - accuracy: 0.5251 - val_loss: 1.4099 - val_accuracy: 0.6359 - 18s/epoch - 70ms/step\n",
            "Epoch 126/200\n",
            "252/252 - 18s - loss: 1.6916 - accuracy: 0.5269 - val_loss: 1.4248 - val_accuracy: 0.6163 - 18s/epoch - 70ms/step\n",
            "Epoch 127/200\n",
            "252/252 - 17s - loss: 1.6678 - accuracy: 0.5253 - val_loss: 1.4144 - val_accuracy: 0.6337 - 17s/epoch - 69ms/step\n",
            "Epoch 128/200\n",
            "252/252 - 17s - loss: 1.6586 - accuracy: 0.5308 - val_loss: 1.4049 - val_accuracy: 0.6369 - 17s/epoch - 69ms/step\n",
            "Epoch 129/200\n",
            "252/252 - 17s - loss: 1.6493 - accuracy: 0.5345 - val_loss: 1.3607 - val_accuracy: 0.6389 - 17s/epoch - 69ms/step\n",
            "Epoch 130/200\n",
            "252/252 - 17s - loss: 1.6828 - accuracy: 0.5257 - val_loss: 1.4095 - val_accuracy: 0.6302 - 17s/epoch - 67ms/step\n",
            "Epoch 131/200\n",
            "252/252 - 17s - loss: 1.6634 - accuracy: 0.5289 - val_loss: 1.3898 - val_accuracy: 0.6372 - 17s/epoch - 67ms/step\n",
            "Epoch 132/200\n",
            "252/252 - 17s - loss: 1.6696 - accuracy: 0.5286 - val_loss: 1.4046 - val_accuracy: 0.6280 - 17s/epoch - 69ms/step\n",
            "Epoch 133/200\n",
            "252/252 - 18s - loss: 1.6709 - accuracy: 0.5264 - val_loss: 1.4304 - val_accuracy: 0.6252 - 18s/epoch - 70ms/step\n",
            "Epoch 134/200\n",
            "252/252 - 18s - loss: 1.6643 - accuracy: 0.5308 - val_loss: 1.3590 - val_accuracy: 0.6387 - 18s/epoch - 70ms/step\n",
            "Epoch 135/200\n",
            "252/252 - 18s - loss: 1.6580 - accuracy: 0.5289 - val_loss: 1.4154 - val_accuracy: 0.6220 - 18s/epoch - 71ms/step\n",
            "Epoch 136/200\n",
            "252/252 - 18s - loss: 1.6637 - accuracy: 0.5273 - val_loss: 1.3382 - val_accuracy: 0.6434 - 18s/epoch - 73ms/step\n",
            "Epoch 137/200\n",
            "252/252 - 18s - loss: 1.6548 - accuracy: 0.5343 - val_loss: 1.3762 - val_accuracy: 0.6384 - 18s/epoch - 70ms/step\n",
            "Epoch 138/200\n",
            "252/252 - 18s - loss: 1.6497 - accuracy: 0.5314 - val_loss: 1.3852 - val_accuracy: 0.6240 - 18s/epoch - 72ms/step\n",
            "Epoch 139/200\n",
            "252/252 - 18s - loss: 1.6707 - accuracy: 0.5266 - val_loss: 1.3666 - val_accuracy: 0.6349 - 18s/epoch - 70ms/step\n",
            "Epoch 140/200\n",
            "252/252 - 18s - loss: 1.6436 - accuracy: 0.5304 - val_loss: 1.3858 - val_accuracy: 0.6310 - 18s/epoch - 70ms/step\n",
            "Epoch 141/200\n",
            "252/252 - 18s - loss: 1.6426 - accuracy: 0.5356 - val_loss: 1.3441 - val_accuracy: 0.6449 - 18s/epoch - 70ms/step\n",
            "Epoch 142/200\n",
            "252/252 - 18s - loss: 1.6734 - accuracy: 0.5251 - val_loss: 1.3688 - val_accuracy: 0.6369 - 18s/epoch - 71ms/step\n",
            "Epoch 143/200\n",
            "252/252 - 18s - loss: 1.6474 - accuracy: 0.5353 - val_loss: 1.3878 - val_accuracy: 0.6312 - 18s/epoch - 72ms/step\n",
            "Epoch 144/200\n",
            "252/252 - 18s - loss: 1.6507 - accuracy: 0.5302 - val_loss: 1.3589 - val_accuracy: 0.6414 - 18s/epoch - 72ms/step\n",
            "Epoch 145/200\n",
            "252/252 - 18s - loss: 1.6413 - accuracy: 0.5312 - val_loss: 1.3571 - val_accuracy: 0.6419 - 18s/epoch - 72ms/step\n",
            "Epoch 146/200\n",
            "252/252 - 18s - loss: 1.6401 - accuracy: 0.5330 - val_loss: 1.3596 - val_accuracy: 0.6384 - 18s/epoch - 71ms/step\n",
            "Epoch 147/200\n",
            "252/252 - 19s - loss: 1.6526 - accuracy: 0.5362 - val_loss: 1.3887 - val_accuracy: 0.6402 - 19s/epoch - 74ms/step\n",
            "Epoch 148/200\n",
            "252/252 - 18s - loss: 1.6324 - accuracy: 0.5394 - val_loss: 1.3596 - val_accuracy: 0.6464 - 18s/epoch - 72ms/step\n",
            "Epoch 149/200\n",
            "252/252 - 18s - loss: 1.6459 - accuracy: 0.5336 - val_loss: 1.3663 - val_accuracy: 0.6414 - 18s/epoch - 72ms/step\n",
            "Epoch 150/200\n",
            "252/252 - 18s - loss: 1.6427 - accuracy: 0.5382 - val_loss: 1.3334 - val_accuracy: 0.6511 - 18s/epoch - 73ms/step\n",
            "Epoch 151/200\n",
            "252/252 - 18s - loss: 1.6227 - accuracy: 0.5425 - val_loss: 1.4210 - val_accuracy: 0.6310 - 18s/epoch - 71ms/step\n",
            "Epoch 152/200\n",
            "252/252 - 18s - loss: 1.6459 - accuracy: 0.5296 - val_loss: 1.3428 - val_accuracy: 0.6481 - 18s/epoch - 71ms/step\n",
            "Epoch 153/200\n",
            "252/252 - 18s - loss: 1.6346 - accuracy: 0.5380 - val_loss: 1.3552 - val_accuracy: 0.6434 - 18s/epoch - 71ms/step\n",
            "Epoch 154/200\n",
            "252/252 - 18s - loss: 1.6244 - accuracy: 0.5447 - val_loss: 1.3499 - val_accuracy: 0.6414 - 18s/epoch - 71ms/step\n",
            "Epoch 155/200\n",
            "252/252 - 18s - loss: 1.6039 - accuracy: 0.5381 - val_loss: 1.3208 - val_accuracy: 0.6474 - 18s/epoch - 71ms/step\n",
            "Epoch 156/200\n",
            "252/252 - 18s - loss: 1.6151 - accuracy: 0.5386 - val_loss: 1.3630 - val_accuracy: 0.6394 - 18s/epoch - 72ms/step\n",
            "Epoch 157/200\n",
            "252/252 - 18s - loss: 1.6118 - accuracy: 0.5411 - val_loss: 1.3547 - val_accuracy: 0.6347 - 18s/epoch - 71ms/step\n",
            "Epoch 158/200\n",
            "252/252 - 18s - loss: 1.6226 - accuracy: 0.5419 - val_loss: 1.3153 - val_accuracy: 0.6551 - 18s/epoch - 71ms/step\n",
            "Epoch 159/200\n",
            "252/252 - 18s - loss: 1.6101 - accuracy: 0.5454 - val_loss: 1.3684 - val_accuracy: 0.6421 - 18s/epoch - 70ms/step\n",
            "Epoch 160/200\n",
            "252/252 - 18s - loss: 1.5962 - accuracy: 0.5496 - val_loss: 1.3817 - val_accuracy: 0.6357 - 18s/epoch - 70ms/step\n",
            "Epoch 161/200\n",
            "252/252 - 18s - loss: 1.6113 - accuracy: 0.5436 - val_loss: 1.3399 - val_accuracy: 0.6446 - 18s/epoch - 70ms/step\n",
            "Epoch 162/200\n",
            "252/252 - 18s - loss: 1.6012 - accuracy: 0.5478 - val_loss: 1.3261 - val_accuracy: 0.6474 - 18s/epoch - 72ms/step\n",
            "Epoch 163/200\n",
            "252/252 - 18s - loss: 1.6136 - accuracy: 0.5473 - val_loss: 1.3263 - val_accuracy: 0.6541 - 18s/epoch - 71ms/step\n",
            "Epoch 164/200\n",
            "252/252 - 18s - loss: 1.6015 - accuracy: 0.5388 - val_loss: 1.3560 - val_accuracy: 0.6474 - 18s/epoch - 70ms/step\n",
            "Epoch 165/200\n",
            "252/252 - 18s - loss: 1.6270 - accuracy: 0.5398 - val_loss: 1.3816 - val_accuracy: 0.6277 - 18s/epoch - 71ms/step\n",
            "Epoch 166/200\n",
            "252/252 - 18s - loss: 1.6318 - accuracy: 0.5421 - val_loss: 1.3398 - val_accuracy: 0.6417 - 18s/epoch - 72ms/step\n",
            "Epoch 167/200\n",
            "252/252 - 18s - loss: 1.6033 - accuracy: 0.5428 - val_loss: 1.3311 - val_accuracy: 0.6496 - 18s/epoch - 72ms/step\n",
            "Epoch 168/200\n",
            "252/252 - 18s - loss: 1.5843 - accuracy: 0.5451 - val_loss: 1.2787 - val_accuracy: 0.6558 - 18s/epoch - 70ms/step\n",
            "Epoch 169/200\n",
            "252/252 - 18s - loss: 1.6035 - accuracy: 0.5434 - val_loss: 1.4078 - val_accuracy: 0.6233 - 18s/epoch - 71ms/step\n",
            "Epoch 170/200\n",
            "252/252 - 18s - loss: 1.5991 - accuracy: 0.5445 - val_loss: 1.3835 - val_accuracy: 0.6320 - 18s/epoch - 71ms/step\n",
            "Epoch 171/200\n",
            "252/252 - 18s - loss: 1.5979 - accuracy: 0.5478 - val_loss: 1.3918 - val_accuracy: 0.6342 - 18s/epoch - 71ms/step\n",
            "Epoch 172/200\n",
            "252/252 - 18s - loss: 1.6058 - accuracy: 0.5466 - val_loss: 1.3031 - val_accuracy: 0.6610 - 18s/epoch - 72ms/step\n",
            "Epoch 173/200\n",
            "252/252 - 18s - loss: 1.5869 - accuracy: 0.5523 - val_loss: 1.3349 - val_accuracy: 0.6436 - 18s/epoch - 71ms/step\n",
            "Epoch 174/200\n",
            "252/252 - 18s - loss: 1.5934 - accuracy: 0.5473 - val_loss: 1.2928 - val_accuracy: 0.6553 - 18s/epoch - 71ms/step\n",
            "Epoch 175/200\n",
            "252/252 - 18s - loss: 1.5805 - accuracy: 0.5530 - val_loss: 1.3332 - val_accuracy: 0.6456 - 18s/epoch - 70ms/step\n",
            "Epoch 176/200\n",
            "252/252 - 18s - loss: 1.5753 - accuracy: 0.5534 - val_loss: 1.3270 - val_accuracy: 0.6496 - 18s/epoch - 72ms/step\n",
            "Epoch 177/200\n",
            "252/252 - 18s - loss: 1.5935 - accuracy: 0.5496 - val_loss: 1.3352 - val_accuracy: 0.6476 - 18s/epoch - 71ms/step\n",
            "Epoch 178/200\n",
            "252/252 - 18s - loss: 1.6081 - accuracy: 0.5458 - val_loss: 1.3513 - val_accuracy: 0.6476 - 18s/epoch - 71ms/step\n",
            "Epoch 179/200\n",
            "252/252 - 18s - loss: 1.5935 - accuracy: 0.5478 - val_loss: 1.3190 - val_accuracy: 0.6536 - 18s/epoch - 72ms/step\n",
            "Epoch 180/200\n",
            "252/252 - 18s - loss: 1.5786 - accuracy: 0.5471 - val_loss: 1.3280 - val_accuracy: 0.6501 - 18s/epoch - 69ms/step\n",
            "Epoch 181/200\n",
            "252/252 - 17s - loss: 1.5835 - accuracy: 0.5533 - val_loss: 1.3059 - val_accuracy: 0.6531 - 17s/epoch - 69ms/step\n",
            "Epoch 182/200\n",
            "252/252 - 18s - loss: 1.5791 - accuracy: 0.5508 - val_loss: 1.3422 - val_accuracy: 0.6429 - 18s/epoch - 71ms/step\n",
            "Epoch 183/200\n",
            "252/252 - 18s - loss: 1.5690 - accuracy: 0.5500 - val_loss: 1.3007 - val_accuracy: 0.6548 - 18s/epoch - 70ms/step\n",
            "Epoch 184/200\n",
            "252/252 - 18s - loss: 1.5688 - accuracy: 0.5539 - val_loss: 1.3572 - val_accuracy: 0.6377 - 18s/epoch - 71ms/step\n",
            "Epoch 185/200\n",
            "252/252 - 18s - loss: 1.5797 - accuracy: 0.5518 - val_loss: 1.3015 - val_accuracy: 0.6471 - 18s/epoch - 71ms/step\n",
            "Epoch 186/200\n",
            "252/252 - 18s - loss: 1.5912 - accuracy: 0.5469 - val_loss: 1.3058 - val_accuracy: 0.6511 - 18s/epoch - 71ms/step\n",
            "Epoch 187/200\n",
            "252/252 - 18s - loss: 1.5615 - accuracy: 0.5564 - val_loss: 1.2890 - val_accuracy: 0.6576 - 18s/epoch - 71ms/step\n",
            "Epoch 188/200\n",
            "252/252 - 18s - loss: 1.5628 - accuracy: 0.5520 - val_loss: 1.3348 - val_accuracy: 0.6392 - 18s/epoch - 70ms/step\n",
            "Epoch 189/200\n",
            "252/252 - 18s - loss: 1.5600 - accuracy: 0.5528 - val_loss: 1.3547 - val_accuracy: 0.6392 - 18s/epoch - 70ms/step\n",
            "Epoch 190/200\n",
            "252/252 - 18s - loss: 1.5732 - accuracy: 0.5542 - val_loss: 1.3420 - val_accuracy: 0.6417 - 18s/epoch - 70ms/step\n",
            "Epoch 191/200\n",
            "252/252 - 18s - loss: 1.5621 - accuracy: 0.5548 - val_loss: 1.3552 - val_accuracy: 0.6392 - 18s/epoch - 71ms/step\n",
            "Epoch 192/200\n",
            "252/252 - 18s - loss: 1.5590 - accuracy: 0.5538 - val_loss: 1.3049 - val_accuracy: 0.6476 - 18s/epoch - 71ms/step\n",
            "Epoch 193/200\n",
            "252/252 - 18s - loss: 1.5682 - accuracy: 0.5595 - val_loss: 1.2908 - val_accuracy: 0.6573 - 18s/epoch - 70ms/step\n",
            "Epoch 194/200\n",
            "252/252 - 18s - loss: 1.5584 - accuracy: 0.5518 - val_loss: 1.3212 - val_accuracy: 0.6484 - 18s/epoch - 71ms/step\n",
            "Epoch 195/200\n",
            "252/252 - 18s - loss: 1.5684 - accuracy: 0.5523 - val_loss: 1.2863 - val_accuracy: 0.6528 - 18s/epoch - 71ms/step\n",
            "Epoch 196/200\n",
            "252/252 - 18s - loss: 1.5590 - accuracy: 0.5561 - val_loss: 1.3077 - val_accuracy: 0.6541 - 18s/epoch - 71ms/step\n",
            "Epoch 197/200\n",
            "252/252 - 18s - loss: 1.5516 - accuracy: 0.5528 - val_loss: 1.3413 - val_accuracy: 0.6461 - 18s/epoch - 71ms/step\n",
            "Epoch 198/200\n",
            "252/252 - 18s - loss: 1.5509 - accuracy: 0.5613 - val_loss: 1.2789 - val_accuracy: 0.6633 - 18s/epoch - 70ms/step\n",
            "Epoch 199/200\n",
            "252/252 - 18s - loss: 1.5587 - accuracy: 0.5501 - val_loss: 1.2842 - val_accuracy: 0.6620 - 18s/epoch - 71ms/step\n",
            "Epoch 200/200\n",
            "252/252 - 18s - loss: 1.5519 - accuracy: 0.5561 - val_loss: 1.3799 - val_accuracy: 0.6357 - 18s/epoch - 71ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 1s 11ms/step - loss: 1.3799 - accuracy: 0.6357\n",
            "1.3798885345458984\n",
            "0.6356858611106873\n",
            "(1, 28, 28, 1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1e2f80f565a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0mfilter_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_featuremaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-1e2f80f565a3>\u001b[0m in \u001b[0;36mget_featuremaps\u001b[0;34m(model, layer_idx, X_batch)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_featuremaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mget_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[1;32m   4227\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4228\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_utils\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4229\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4231\u001b[0m     \u001b[0mwrap_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[0;32m--> 144\u001b[0;31m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[0;32m--> 144\u001b[0;31m                   for t in tf.nest.flatten(inputs)]):\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional_utils.py\u001b[0m in \u001b[0;36mis_input_keras_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     45\u001b[0m   \"\"\"\n\u001b[1;32m     46\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnode_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: 0"
          ]
        }
      ]
    }
  ]
}